<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<title>Cross-Domain and Disentangled Face Manipulation with 3D Guidance
</title>
	<!-- Fonts and stuff -->
	
	<link rel="stylesheet" type="text/css" href="./css/project.css" media="screen">
	<link rel="stylesheet" type="text/css" media="screen" href="./css/iconize.css">
	
</head>

<body>
	<div id="content">
		<div id="content-inner">

			<div class="section head">

				<h1>Cross-Domain and Disentangled Face Manipulation with 3D Guidance</h1>
				<div class="authors">
					<a href="https://cassiepython.github.io/" target="_blank">Can Wang</a><sup> 1</sup>&#160;&#160;
					<a href="https://mlchai.com/" target="_blank">Menglei Chai</a><sup> 2</sup>&#160;&#160;
					<a href="http://mingminghe.com/" target="_blank">Mingming He</a><sup> 3</sup>&#160;&#160;
					<a href="http://www.dongdongchen.bid/" target="_blank">Dongdong Chen</a><sup> 4</sup>&#160;&#160;
					<a href="https://liaojing.github.io/html/" target="_blank">Jing Liao</a><sup> 1*</sup>&#160;&#160;
				</div>

				<div class="affiliations">
					<sup>1</sup>City University of Hong Kong&#160;&#160;
					<sup>2</sup>Creative Vision, Snap Inc.&#160;&#160;
					<sup>3</sup>USC Institute for Creative Technologies&#160;&#160;
					<sup>4</sup>Microsoft Cloud AI&#160;&#160;
					<sup>*</sup>Corresponding Author&#160;&#160;
				</div>

			</div>
			
			
			

			<div class="section abstract">
			</div>

			<div class="teaser">
				<img src = "./images/teaser.png">
			</div>
			
			<div class="section codepaper">
				<center>
				<ul>
					<li class="grid">
						<div class="griditem2">
						<a href="" class="imageLink2"><img src = "./images/paper.png"></a><br/>
							<font size="3" color="#004B97"><b>Paper</b></font><br/>
						</div>
					</li>
					<li class="grid">
						<div class="griditem2">
						<a href="" class="imageLink2"><img src = "./images/code.png"></a><br/>
							<font size="3" color="#004B97"><b>Code</b></font><br/>
						</div>
					</li>
				</ul>
				</center>
			</div>
			
			
			<div class="section video">
				<h2>Video</h2> </br>
				<div class="section teaser">
					<iframe width="640" height="360" src="./data/video.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
				</div>
			</div>
			

			<div class="section abstract">
				<h2>Abstract</h2> </br>
				<p>
Face image manipulation via three-dimensional guidance has been widely applied in various interactive scenarios due to its semantically-meaningful understanding and user-friendly controllability. However, existing 3D-morphable-model-based manipulation methods are not directly applicable to out-of-domain faces, such as non-photorealistic paintings, cartoon portraits, or even animals, mainly due to the formidable difficulties in building the model for each specific face domain. To overcome this challenge, we propose, as far as we know, the first method to manipulate faces in arbitrary domains using human 3DMM. This is achieved through two major steps: 1) disentangled mapping from 3DMM parameters to the latent space embedding of a pre-trained StyleGAN2 that guarantees disentangled and precise controls for each semantic attribute; and 2) cross-domain adaptation that bridges domain discrepancies and makes human 3DMM applicable to out-of-domain faces by enforcing a consistent latent space embedding. Experiments and comparisons demonstrate the superiority of our high-quality semantic manipulation method on a variety of face domains with all major 3D facial attributes controllable â€“ pose, expression, shape, albedo, and illumination. Moreover, we develop an intuitive editing interface to support user-friendly control and instant feedback.
</p>
			</div>

			<div class="section results">
				<h2>More Results</h2>
				<center>
				<ul>
					<li class="grid">
						<div class="griditem">
						<a href="./web_show_japan.html" class="imageLink"><img src = "./images/japan.png"></a><br/>
							Ukiyo-e Face<br/>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
						<a href="./web_show_dog.html" class="imageLink"><img src = "./images/dog.png"></a><br/>
							Dog<br/>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
						<a href="./web_show_portrait.html" class="imageLink"><img src = "./images/portrait.png"></a><br/>
							Portrait</a><br>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
						<a href="./web_show_anime.html" class="imageLink"><img src = "./images/anime.png"></a><br/>
							Anime</a><br>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
						<a href="./web_show_disney.html" class="imageLink"><img src = "./images/disney.png"></a><br/>
							Disney Face</a><br>
						</div>
					</li>
				</ul>
				</center>
			</div>

			<div class="section list">
				<h2>Citation</h2>
				<div class="section bibtex">
					<pre>@article{wang2021crossdomain,
  title={Cross-Domain and Disentangled Face Manipulation with 3D Guidance},
  author={Wang, Can and Chai, Menglei and He, Mingming and Chen, Dongdong and Liao, Jing},
  journal={arXiv preprint arXiv:2103.14331},
  year={2021}
}</pre>
		  </div>
			</div>
			<div class="section">
				<hr class="smooth">
				This page is highly borrowed from <a href="https://gvv.mpi-inf.mpg.de/projects/PIE/">PIE</a>. 
			</div>

		</div>
	</div>

</body></html>
